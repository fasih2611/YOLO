import gc
import sys
import os
import time
from tqdm import tqdm
import torch
import torchvision.transforms as transforms
import onnxruntime
from ultralytics import YOLO
import logging
from statistics import mean, stdev
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval
import numpy as np
from PIL import Image
import csv
sys.path.append('./YOLOv8-test')
from utils.util import non_max_suppression # type: ignore
# Global variables
batch_size = 1
class_no = 80
preprocess_time = 0

# Set up logging
logging.basicConfig(filename='yolo_precision_evaluation.log', level=logging.INFO,
                    format='- %(levelname)s - %(message)s')

def write_results_to_csv(results, filename='yolo_precision_results.csv'):
    with open(filename, 'w', newline='') as csvfile:
        fieldnames = ['Model', 'Image Size', 'Preprocess Time', 'Inference Time', 'Post-processing Time', 'mAP@0.5', 'mAP@0.5:0.95']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

        writer.writeheader()
        for image_size, size_results in results.items():
            for model, model_results in size_results.items():
                writer.writerow({
                    'Model': model,
                    'Image Size': image_size,
                    'Preprocess Time': f'{model_results[0]:.4f}',
                    'Inference Time': f'{model_results[1]:.4f}',
                    'Post-processing Time': f'{model_results[2]:.4f}',
                    'mAP@0.5': f'{model_results[3]:.4f}',
                    'mAP@0.5:0.95': f'{model_results[4]:.4f}'
                })

def preprocess_images(image_folder, input_size):
    resize_transform = transforms.Compose([
        transforms.Resize((input_size, input_size)),
        transforms.ToTensor(),
    ])

    image_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]
    batches = []
    preprocess_times = []

    for i in range(0, len(image_files), batch_size):
        batch = []
        for j in range(i, min(i + batch_size, len(image_files))):
            start_time = time.perf_counter()
            image = Image.open(os.path.join(image_folder, image_files[j]))
            tensor = resize_transform(image)
            tensor = tensor / 255
            end_time = time.perf_counter()
            preprocess_times.append(end_time - start_time)
            
            batch.append(tensor)
        batches.append(torch.stack(batch))
    
    global preprocess_time
    preprocess_time = mean(preprocess_times)
    print(f"Average Preprocessing Time per image ({input_size}x{input_size}): {preprocess_time:.4f} seconds")
    return batches, image_files

def run_inference(model_func, batches):
    inference_times = []
    post_processing_times = []
    all_predictions = []
    
    for batch in tqdm(batches, desc="Running inference"):
        start_time = time.perf_counter()
        pred = model_func(batch)
        end_time = time.perf_counter()
        inference_times.append(end_time - start_time)
        
        # Post-processing
        start_time = time.perf_counter()
        processed_pred = non_max_suppression(torch.tensor(pred[0]) if not isinstance(pred, torch.Tensor) else pred)
        end_time = time.perf_counter()
        post_processing_times.append(end_time - start_time)
        
        all_predictions.extend(processed_pred)
    
    global preprocess_time
    avg_inference_time = mean(inference_times)
    avg_post_processing_time = mean(post_processing_times)
    
    return preprocess_time, avg_inference_time, avg_post_processing_time, all_predictions

def inference_ultralytics(model, batches):
    def model_func(batch):
        return model.model(batch)
    
    return run_inference(model_func, batches)

def inference_onnx(onnx_path, batches):
    session = onnxruntime.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])
    input_name = session.get_inputs()[0].name

    def model_func(batch):
        return session.run(None, {input_name: batch.numpy()})
    
    return run_inference(model_func, batches)

def calculate_precision(predictions, coco_gt, image_ids, input_size):
    coco_dt = COCO()
    coco_dt.dataset = {'images': [], 'categories': coco_gt.dataset['categories'], 'annotations': []}
    coco_dt.createIndex()

    ann_id = 1
    for i, pred in enumerate(predictions):
        image_id = int(image_ids[i].split('.')[0])
        for *xyxy, conf, cls in pred:
            x1, y1, x2, y2 = xyxy
            w = x2 - x1
            h = y2 - y1
            ann = {
                'image_id': image_id,
                'category_id': int(cls) + 1,  # COCO categories start from 1
                'bbox': [x1, y1, w, h],
                'score': float(conf),
                'area': float(w * h),
                'iscrowd': 0,
                'id': ann_id
            }
            coco_dt.dataset['annotations'].append(ann)
            ann_id += 1
        coco_dt.dataset['images'].append({'id': image_id, 'file_name': image_ids[i]})

    coco_dt.createIndex()
    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')
    coco_eval.params.imgIds = [int(img_id.split('.')[0]) for img_id in image_ids]
    coco_eval.evaluate()
    coco_eval.accumulate()
    coco_eval.summarize()

    return coco_eval.stats[1], coco_eval.stats[0]  # mAP@0.5, mAP@0.5:0.95

def run_comparisons(input_size, model_type):
    print(f"\nRunning comparisons for {input_size}x{input_size} images:")
    ultralytics_model = YOLO(f'{model_type}.pt')
    ultralytics_model.eval()
    # Load COCO annotations
    coco_gt = COCO('./datasets/coco2017/annotations/instances_val2017.json')
    
    # Prepare data
    batches, image_ids = preprocess_images('./datasets/coco2017/images/val2017', input_size)

    
    ultralytics_model.fuse()

    ultralytics_model.export(format="onnx", batch=batch_size,
                             imgsz=input_size, simplify=True, opset=13)
    
    # Run inferences
    ultralytics_results = inference_ultralytics(ultralytics_model, batches)
    ultralytics_onnx_results = inference_onnx(f'./{model_type}.onnx', batches)
    
    # Calculate precision
    ultralytics_map50, ultralytics_map = calculate_precision(ultralytics_results[3], coco_gt, image_ids, input_size)
    ultralytics_onnx_map50, ultralytics_onnx_map = calculate_precision(ultralytics_onnx_results[3], coco_gt, image_ids, input_size)
    
    del ultralytics_model
    gc.collect()

    return {
        f'{model_type} ultralytics': ultralytics_results[:3] + (ultralytics_map50, ultralytics_map),
        f'{model_type} ultralytics_onnx': ultralytics_onnx_results[:3] + (ultralytics_onnx_map50, ultralytics_onnx_map),
    }

def main():
    sizes = [640]
    models = ['yolov8n', 'yolov5n'] 
    results = {}
    for model in models:
        for size in sizes:
            results[size] = run_comparisons(size, model)
        write_results_to_csv(results, filename=f'{model} - precision comparison.csv')

if __name__ == "__main__":
    main()